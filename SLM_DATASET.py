import os
import json
import re
import time
from tqdm import tqdm
import requests
from concurrent.futures import ThreadPoolExecutor, as_completed
import logging
import random

# ========== 0. é…ç½® ==========
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# --- DeepSeek API é…ç½® ---
API_KEY = os.getenv("DEEPSEEK_API_KEY", "sk-4ba5df9144f14d5e95c86caf2fe5240d")
API_URL = os.getenv("DEEPSEEK_API_URL", "https://api.deepseek.com/v1/chat/completions")
MODEL = os.getenv("DEEPSEEK_MODEL", "deepseek-chat")

# --- æ•°æ®é›†ç”Ÿæˆé…ç½® ---
LAW_LIST = [
    "ä¸­åäººæ°‘å…±å’Œå›½åˆ‘æ³•", "ä¸­åäººæ°‘å…±å’Œå›½æ°‘æ³•å…¸", "å…¬å¸æ³•", "è¯åˆ¸æ³•", "æµ·å•†æ³•",
    "æ°‘äº‹è¯‰è®¼æ³•", "åˆ‘äº‹è¯‰è®¼æ³•", "æ°‘ç”¨èˆªç©ºæ³•", "å…¬å®‰æœºå…³åŠç†è¡Œæ”¿æ¡ˆä»¶ç¨‹åºè§„å®š",
    "å…¬å®‰æœºå…³åŠç†åˆ‘äº‹æ¡ˆä»¶ç¨‹åºè§„å®š", "äººæ°‘æ£€å¯Ÿé™¢åˆ‘äº‹è¯‰è¨Ÿè§„åˆ™",
    "æœ€é«˜äººæ°‘æ³•é™¢å…³äºé€‚ç”¨ã€Šæ°‘äº‹è¯‰è®¼æ³•ã€‹çš„è§£é‡Š", "æœ€é«˜äººæ°‘æ³•é™¢å…³äºé€‚ç”¨ã€Šåˆ‘äº‹è¯‰è®¼æ³•ã€‹çš„è§£é‡Š"
]
TOPICS_PER_LAW = 15
QUESTIONS_PER_TOPIC = 5

# --- æ€§èƒ½é…ç½® ---
OUTPUT_FILE = "synthetic_query_rewriter_dataset_fast_1k.jsonl"
MAX_WORKERS = 8      # å¹¶è¡Œå¤„ç†çš„çº¿ç¨‹æ•°
TOPIC_BATCH_SIZE = 5   # æ¯æ¬¡APIè°ƒç”¨ç”Ÿæˆé—®é¢˜çš„æ‰¹å¤„ç†å¤§å°
QUESTION_BATCH_SIZE = 10 # æ¯æ¬¡APIè°ƒç”¨è½¬æ¢é—®é¢˜çš„æ‰¹å¤„ç†å¤§å°

# åˆ›å»ºä¸€ä¸ªä¼šè¯ä»¥å¤ç”¨è¿æ¥
session = requests.Session()
session.headers.update({
    "Content-Type": "application/json",
    "Authorization": f"Bearer {API_KEY}"
})

# ========== 1. API è°ƒç”¨ä¸è§£æå‡½æ•° ==========

def call_api(system_message, user_prompt, temperature=0.5, use_json_mode=False):
    """é€šç”¨çš„APIè°ƒç”¨å‡½æ•°"""
    payload = {
        "model": MODEL,
        "messages": [{"role": "system", "content": system_message}, {"role": "user", "content": user_prompt}],
        "temperature": temperature,
        "max_tokens": 4096, # ä¸ºæ‰¹é‡ä»»åŠ¡æä¾›å……è¶³ç©ºé—´
    }
    if use_json_mode:
        payload["response_format"] = {"type": "json_object"}
    
    try:
        response = session.post(API_URL, json=payload, timeout=180) # å»¶é•¿è¶…æ—¶
        response.raise_for_status()
        return response.json()['choices'][0]['message']['content'].strip()
    except Exception as e:
        logging.error(f"APIè°ƒç”¨å¤±è´¥: {e}")
        return None

def safe_json_loads(json_string, expected_keys):
    """æ›´å®‰å…¨åœ°è§£æJSONï¼Œå¹¶éªŒè¯å…¶ç»“æ„"""
    try:
        data = json.loads(json_string)
        if all(key in data for key in expected_keys):
            return data
        else:
            logging.warning(f"è§£æçš„JSONç¼ºå°‘é”®ã€‚éœ€è¦: {expected_keys}, å¾—åˆ°: {data.keys()}")
            return None
    except json.JSONDecodeError:
        logging.warning(f"æ— æ³•è§£æJSONå­—ç¬¦ä¸²: {json_string[:200]}...")
        return None

# ========== 2. å¹¶è¡Œ&æ‰¹é‡çš„æ•°æ®ç”Ÿæˆå·¥ä½œæµ ==========

def generate_topics_for_law(law_name):
    """é˜¶æ®µ1: ä¸ºä¸€éƒ¨æ³•å¾‹ç”Ÿæˆå¤šä¸ªæ ¸å¿ƒä¸»é¢˜"""
    prompt = f"è¯·é’ˆå¯¹ã€Š{law_name}ã€‹ï¼Œæ„æ€å‡º {TOPICS_PER_LAW} ä¸ªæ™®é€šæ°‘ä¼—æœ€å…³å¿ƒçš„æ ¸å¿ƒæ³•å¾‹ä¸»é¢˜æˆ–åœºæ™¯ã€‚æ¯ä¸ªä¸»é¢˜ä¸€è¡Œï¼Œä¸è¦æœ‰ä»»ä½•å¤šä½™çš„è§£é‡Šã€‚"
    response = call_api("ä½ æ˜¯ä¸€ä½èµ„æ·±çš„æ³•å¾‹ä¸“å®¶å’Œæ•™è‚²å®¶ã€‚", prompt, temperature=0.7)
    if response:
        return [re.sub(r'^\d+\.\s*', '', line).strip() for line in response.split('\n') if line.strip()]
    return []

def batch_generate_questions(topic_batch_with_laws):
    """é˜¶æ®µ2: ä¸ºä¸€æ‰¹ä¸»é¢˜æ‰¹é‡ç”Ÿæˆå£è¯­åŒ–é—®é¢˜"""
    formatted_topics = "\n".join([f"{i+1}. {law}: {topic}" for i, (law, topic) in enumerate(topic_batch_with_laws)])
    prompt = f"""
è¯·ä¸ºä»¥ä¸‹ {len(topic_batch_with_laws)} ä¸ªæ³•å¾‹ä¸»é¢˜ï¼Œå„è‡ªç”Ÿæˆ {QUESTIONS_PER_TOPIC} ä¸ªæ™®é€šäººä¼šé—®çš„å£è¯­åŒ–é—®é¢˜ã€‚
ä¸¥æ ¼æŒ‰JSONæ ¼å¼è¿”å›ï¼Œé”®ä¸º "results"ï¼Œå€¼ä¸ºä¸€ä¸ªæ•°ç»„ï¼Œæ•°ç»„æ¯ä¸ªå…ƒç´ æ˜¯å¯¹åº”ä¸»é¢˜çš„é—®é¢˜åˆ—è¡¨ï¼ˆå­—ç¬¦ä¸²æ•°ç»„ï¼‰ã€‚

å¾…å¤„ç†ä¸»é¢˜ï¼š
{formatted_topics}
"""
    response = call_api("ä½ æ˜¯ä¸€ä½å†…å®¹åˆ›ä½œè€…ï¼Œæ“…é•¿æ¨¡ä»¿æ™®é€šç½‘æ°‘çš„å£å»æé—®ã€‚", prompt, temperature=0.8, use_json_mode=True)
    if response:
        data = safe_json_loads(response, ["results"])
        if data and isinstance(data['results'], list) and len(data['results']) == len(topic_batch_with_laws):
            return [q for sublist in data['results'] for q in sublist if q and '?' in q]
    return []

def batch_create_training_samples(question_batch):
    """é˜¶æ®µ3: å°†ä¸€æ‰¹é—®é¢˜æ‰¹é‡è½¬æ¢ä¸ºç»“æ„åŒ–çš„JSONè¾“å‡º"""
    formatted_questions = "\n".join([f"{i+1}. {q}" for i, q in enumerate(question_batch)])
    prompt = f"""
è¯·åˆ†æä»¥ä¸‹ {len(question_batch)} ä¸ªç”¨æˆ·çš„æ³•å¾‹é—®é¢˜ï¼Œå¹¶ä¸ºæ¯ä¸€ä¸ªé—®é¢˜ç”Ÿæˆä¸€ä¸ªç»“æ„åŒ–çš„JSONå¯¹è±¡ã€‚
ä¸¥æ ¼æŒ‰JSONæ ¼å¼è¿”å›ï¼Œæœ€å¤–å±‚é”®ä¸º "results"ï¼Œå€¼ä¸ºä¸€ä¸ªJSONæ•°ç»„ï¼Œæ•°ç»„çš„æ¯ä¸ªå…ƒç´ æ˜¯å¯¹åº”é—®é¢˜çš„ç»“æ„åŒ–è¾“å‡ºã€‚
æ¯ä¸ªç»“æ„åŒ–è¾“å‡ºå¯¹è±¡å¿…é¡»åŒ…å«ä¸¤ä¸ªé”®:
1. `keywords_for_search`: åŒ…å«3-5ä¸ªæ ¸å¿ƒæ³•å¾‹æœ¯è¯­çš„æ•°ç»„ã€‚
2. `query_for_vector_search`: ä¸€ä¸ªä¹¦é¢åŒ–çš„ã€æ¦‚æ‹¬æ€§çš„æŸ¥è¯¢å­—ç¬¦ä¸²ã€‚

å¾…å¤„ç†çš„é—®é¢˜:
{formatted_questions}
"""
    response = call_api("ä½ æ˜¯ä¸€ä¸ªé¡¶çº§çš„æ³•å¾‹æŸ¥è¯¢åˆ†æå¼•æ“ã€‚", prompt, temperature=0.1, use_json_mode=True)
    samples = []
    if response:
        data = safe_json_loads(response, ["results"])
        if data and isinstance(data['results'], list) and len(data['results']) == len(question_batch):
            for i, res_obj in enumerate(data['results']):
                if isinstance(res_obj, dict) and 'keywords_for_search' in res_obj and 'query_for_vector_search' in res_obj:
                    samples.append({
                        "instruction": "ä½ æ˜¯ä¸€ä¸ªæ³•å¾‹æŸ¥è¯¢åŠ©æ‰‹ã€‚è¯·åˆ†æç”¨æˆ·çš„æ³•å¾‹é—®é¢˜ï¼Œå¹¶å°†å…¶è½¬æ¢ä¸ºç»“æ„åŒ–çš„JSONå¯¹è±¡...",
                        "input": question_batch[i],
                        "output": json.dumps(res_obj, ensure_ascii=False)
                    })
    return samples

# ========== 3. ä¸»æ‰§è¡Œæµç¨‹ ==========

if __name__ == "__main__":
    logging.info("--- å¼€å§‹é«˜é€Ÿç”Ÿæˆé«˜è´¨é‡çš„æŸ¥è¯¢é‡å†™å¾®è°ƒæ•°æ®é›† ---")
    
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        # --- é˜¶æ®µ1: å¹¶è¡Œç”Ÿæˆæ‰€æœ‰ä¸»é¢˜ ---
        law_to_topics_futures = {executor.submit(generate_topics_for_law, law): law for law in LAW_LIST}
        topics_with_laws = []
        for future in tqdm(as_completed(law_to_topics_futures), total=len(LAW_LIST), desc="é˜¶æ®µ1: ç”Ÿæˆä¸»é¢˜"):
            law = law_to_topics_futures[future]
            try:
                topics = future.result()
                topics_with_laws.extend([(law, topic) for topic in topics])
            except Exception as e:
                logging.error(f"ä¸ºã€Š{law}ã€‹ç”Ÿæˆä¸»é¢˜å¤±è´¥: {e}")
        
        random.shuffle(topics_with_laws)
        logging.info(f"æˆåŠŸç”Ÿæˆ {len(topics_with_laws)} ä¸ªä¸»é¢˜ï¼Œå‡†å¤‡ç”Ÿæˆé—®é¢˜...")

        # --- é˜¶æ®µ2: å¹¶è¡Œ&æ‰¹é‡ç”Ÿæˆæ‰€æœ‰é—®é¢˜ ---
        topic_batches = [topics_with_laws[i:i + TOPIC_BATCH_SIZE] for i in range(0, len(topics_with_laws), TOPIC_BATCH_SIZE)]
        batch_to_questions_futures = {executor.submit(batch_generate_questions, batch): batch for batch in topic_batches}
        all_questions = []
        for future in tqdm(as_completed(batch_to_questions_futures), total=len(topic_batches), desc="é˜¶æ®µ2: ç”Ÿæˆé—®é¢˜"):
            try:
                all_questions.extend(future.result())
            except Exception as e:
                logging.error(f"ä¸€ä¸ªé—®é¢˜ç”Ÿæˆæ‰¹æ¬¡å¤±è´¥: {e}")
        
        random.shuffle(all_questions)
        logging.info(f"æˆåŠŸç”Ÿæˆ {len(all_questions)} ä¸ªé—®é¢˜ï¼Œå‡†å¤‡è½¬æ¢ä¸ºè®­ç»ƒæ ·æœ¬...")

        # --- é˜¶æ®µ3: å¹¶è¡Œ&æ‰¹é‡è½¬æ¢é—®é¢˜ä¸ºè®­ç»ƒæ ·æœ¬ ---
        with open(OUTPUT_FILE, 'w', encoding='utf-8') as outfile:
            question_batches = [all_questions[i:i + QUESTION_BATCH_SIZE] for i in range(0, len(all_questions), QUESTION_BATCH_SIZE)]
            batch_to_samples_futures = {executor.submit(batch_create_training_samples, batch): batch for batch in question_batches}
            
            for future in tqdm(as_completed(batch_to_samples_futures), total=len(question_batches), desc="é˜¶æ®µ3: è½¬æ¢æ ·æœ¬"):
                try:
                    samples = future.result()
                    for sample in samples:
                        outfile.write(json.dumps(sample, ensure_ascii=False) + '\n')
                except Exception as e:
                    logging.error(f"ä¸€ä¸ªæ ·æœ¬è½¬æ¢æ‰¹æ¬¡å¤±è´¥: {e}")

    logging.info(f"\nğŸ‰ğŸ‰ğŸ‰ é«˜æ€§èƒ½æ•°æ®é›†ç”Ÿæˆå®Œæ¯•ï¼ğŸ‰ğŸ‰ğŸ‰")
    logging.info(f"æ–‡ä»¶å·²ä¿å­˜è‡³: {OUTPUT_FILE}")

# LAW MASTER 系统设计文档

**版本**: 1.0.0  
**日期**: 2025-01-29  
**状态**: 正式发布  
**作者**: LAW MASTER Team

---

## 文档修订历史

| 版本 | 日期 | 修订人 | 修订内容 |
|------|------|--------|----------|
| 0.1.0 | 2024-10-01 | Team | 初始版本 |
| 0.5.0 | 2024-12-15 | Team | 添加三模型架构 |
| 1.0.0 | 2025-01-29 | Team | 正式发布版本 |

---

## 目录

- [1. 概述](#1-概述)
  - [1.1 项目背景](#11-项目背景)
  - [1.2 设计目标](#12-设计目标)
  - [1.3 技术栈](#13-技术栈)
- [2. 系统架构](#2-系统架构)
  - [2.1 总体架构](#21-总体架构)
  - [2.2 分层架构](#22-分层架构)
  - [2.3 部署架构](#23-部署架构)
- [3. 模块设计](#3-模块设计)
  - [3.1 核心模块](#31-核心模块)
  - [3.2 支撑模块](#32-支撑模块)
  - [3.3 工具模块](#33-工具模块)
- [4. 接口设计](#4-接口设计)
  - [4.1 内部接口](#41-内部接口)
  - [4.2 外部接口](#42-外部接口)
  - [4.3 数据接口](#43-数据接口)
- [5. 数据结构设计](#5-数据结构设计)
  - [5.1 核心数据结构](#51-核心数据结构)
  - [5.2 配置数据结构](#52-配置数据结构)
  - [5.3 存储数据结构](#53-存储数据结构)
- [6. 关键流程设计](#6-关键流程设计)
  - [6.1 查询处理流程](#61-查询处理流程)
  - [6.2 检索流程](#62-检索流程)
  - [6.3 答案生成流程](#63-答案生成流程)
- [7. 性能设计](#7-性能设计)
  - [7.1 性能指标](#71-性能指标)
  - [7.2 优化策略](#72-优化策略)
  - [7.3 扩展性设计](#73-扩展性设计)
- [8. 安全设计](#8-安全设计)
  - [8.1 数据安全](#81-数据安全)
  - [8.2 模型安全](#82-模型安全)
  - [8.3 访问控制](#83-访问控制)
- [9. 异常处理](#9-异常处理)
- [10. 测试设计](#10-测试设计)
- [11. 部署运维](#11-部署运维)

---

## 1. 概述

### 1.1 项目背景

LAW MASTER是一个基于大语言模型与检索增强生成（RAG）架构的智能法律助手系统，旨在通过AI技术弥合法律服务的知识鸿沟，让普通人能够获得专业、准确、易懂的法律咨询服务。

**核心问题**:
- 法律咨询费用高昂，普通人难以承担
- 法律术语专业复杂，理解门槛高
- 法律知识更新快，信息检索困难

**解决方案**:
- 使用小型语言模型（SLM）进行专业化微调
- 采用混合检索技术提升召回准确率
- 三模型协同工作，分工明确，性能优异

### 1.2 设计目标

#### 功能目标
- ✅ 支持自然语言法律问题查询
- ✅ 准确检索相关法律条文（Top-3命中率 > 40%）
- ✅ 生成专业且通俗易懂的法律解答
- ✅ 支持多轮对话和上下文理解

#### 性能目标
- ⚡ 单次查询响应时间 < 2秒
- 🎯 法条检索准确率 > 40%（Top-3）
- 💾 单卡显存占用 < 32GB
- 🚀 推理吞吐量 > 500 tokens/s

#### 质量目标
- 📝 代码覆盖率 > 80%
- 🔒 系统可用性 > 99.5%
- 📊 答案准确性 > 90%（人工评估）
- 🛡️ 安全漏洞数量 = 0

### 1.3 技术栈

#### 深度学习框架
```yaml
框架层:
  - PyTorch: 2.1.0 (MindIE 2.0.RC2)
  - Transformers: 4.36.0
  - PEFT: 0.7.0
  - Datasets: 2.14.0

计算平台:
  - 硬件: Huawei Ascend 910B (64GB HBM)
  - 编译工具链: CANN 8.1.RC1
  - 操作系统: openEuler 24.03
  - Python: 3.11
```

#### 数据处理
```yaml
向量检索:
  - FAISS: 1.7.4
  - Sentence-Transformers: 2.2.2
  - NumPy: 1.24.3

文本处理:
  - Jieba: 0.42.1
  - Readability-lxml: 0.8.1
  - BeautifulSoup4: 4.12.2
```

#### 工程化工具
```yaml
开发工具:
  - 日志: Rich 13.7.0
  - 配置: YAML/JSON
  - 测试: Pytest
  - 文档: Sphinx
```

---

## 2. 系统架构

### 2.1 总体架构

LAW MASTER采用**三层架构 + 三模型协同**的设计模式：

```
┌─────────────────────────────────────────────────────────────────┐
│                          用户交互层                               │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐  ┌──────────┐       │
│  │ Web界面  │  │ API接口  │  │ CLI工具  │  │ SDK客户端│       │
│  └──────────┘  └──────────┘  └──────────┘  └──────────┘       │
└────────────────────────────┬────────────────────────────────────┘
                             │
┌────────────────────────────┼────────────────────────────────────┐
│                         业务逻辑层                               │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │                     核心处理流水线                         │  │
│  │  ┌──────────┐   ┌──────────┐   ┌──────────┐            │  │
│  │  │查询重写   │-->│混合检索   │-->│答案生成   │            │  │
│  │  │SLM-Rewriter│  │Retriever │  │SLM-Generator│         │  │
│  │  └──────────┘   └──────────┘   └──────────┘            │  │
│  └──────────────────────────────────────────────────────────┘  │
│  ┌──────────────────────────────────────────────────────────┐  │
│  │                     支撑服务模块                           │  │
│  │  [配置管理] [日志系统] [缓存服务] [监控告警]              │  │
│  └──────────────────────────────────────────────────────────┘  │
└────────────────────────────┬────────────────────────────────────┘
                             │
┌────────────────────────────┼────────────────────────────────────┐
│                          数据存储层                              │
│  ┌──────────┐  ┌──────────┐  ┌──────────┐  ┌──────────┐       │
│  │模型仓库  │  │向量数据库│  │知识图谱  │  │配置中心  │       │
│  │(LoRA)    │  │(FAISS)   │  │(JSON)    │  │(YAML)    │       │
│  └──────────┘  └──────────┘  └──────────┘  └──────────┘       │
└─────────────────────────────────────────────────────────────────┘
```

### 2.2 分层架构

#### 2.2.1 表示层 (Presentation Layer)

**职责**: 处理用户交互，数据展示和输入验证

```python
表示层组件:
├── web_interface/          # Web前端界面
│   ├── templates/          # 页面模板
│   ├── static/             # 静态资源
│   └── app.py              # Flask/FastAPI应用
├── api_gateway/            # RESTful API网关
│   ├── routes.py           # 路由定义
│   ├── validators.py       # 请求验证
│   └── serializers.py      # 数据序列化
└── cli_interface/          # 命令行工具
    └── main.py             # CLI入口
```

**关键接口**:
```python
# RESTful API接口
POST /api/v1/query          # 提交法律问题
GET  /api/v1/history        # 查询历史记录
GET  /api/v1/health         # 健康检查
POST /api/v1/feedback       # 用户反馈
```

#### 2.2.2 业务逻辑层 (Business Logic Layer)

**职责**: 实现核心业务逻辑和算法

```python
业务逻辑层组件:
├── pipeline/               # 处理流水线
│   ├── query_pipeline.py   # 查询处理流程
│   ├── rewrite_service.py  # 查询重写服务
│   ├── retrieval_service.py# 检索服务
│   └── generation_service.py# 生成服务
├── models/                 # 模型管理
│   ├── model_loader.py     # 模型加载器
│   ├── query_rewriter.py   # 查询重写模型
│   └── answer_generator.py # 答案生成模型
└── retriever/              # 检索系统
    ├── hybrid_retriever.py # 混合检索器
    ├── vector_search.py    # 向量检索
    └── keyword_search.py   # 关键词检索
```

#### 2.2.3 数据访问层 (Data Access Layer)

**职责**: 管理数据持久化和访问

```python
数据访问层组件:
├── repositories/           # 数据仓库
│   ├── model_repository.py # 模型仓库
│   ├── vector_repository.py# 向量数据仓库
│   └── cache_repository.py # 缓存仓库
├── indices/                # 索引管理
│   ├── faiss_index.py      # FAISS索引
│   └── inverted_index.py   # 倒排索引
└── storage/                # 存储管理
    ├── file_storage.py     # 文件存储
    └── db_storage.py       # 数据库存储
```

### 2.3 部署架构

#### 2.3.1 单机部署架构

```
┌─────────────────────────────────────────────────┐
│              Huawei Ascend 910B                  │
│  ┌───────────────────────────────────────────┐  │
│  │         Application Container             │  │
│  │  ┌─────────────┐  ┌─────────────┐        │  │
│  │  │ Query       │  │ Answer      │        │  │
│  │  │ Rewriter    │  │ Generator   │        │  │
│  │  │ Model       │  │ Model       │        │  │
│  │  └─────────────┘  └─────────────┘        │  │
│  │  ┌─────────────────────────────┐         │  │
│  │  │   Hybrid Retriever          │         │  │
│  │  │  ┌─────────┐  ┌──────────┐ │         │  │
│  │  │  │ FAISS   │  │ Inverted │ │         │  │
│  │  │  │ Index   │  │ Index    │ │         │  │
│  │  │  └─────────┘  └──────────┘ │         │  │
│  │  └─────────────────────────────┘         │  │
│  └───────────────────────────────────────────┘  │
│  ┌───────────────────────────────────────────┐  │
│  │         Data Storage                      │  │
│  │  [Models] [Vectors] [Configs] [Logs]     │  │
│  └───────────────────────────────────────────┘  │
└─────────────────────────────────────────────────┘
```

#### 2.3.2 分布式部署架构（规划中）

```
┌────────────────┐      ┌────────────────┐
│  Load Balancer │      │  API Gateway   │
└───────┬────────┘      └───────┬────────┘
        │                       │
        ▼                       ▼
┌─────────────────────────────────────────┐
│        Service Mesh (K8s)                │
│  ┌──────────┐  ┌──────────┐  ┌────────┐│
│  │ Rewriter │  │ Generator│  │Retriever││
│  │ Service  │  │ Service  │  │ Service ││
│  └──────────┘  └──────────┘  └────────┘│
└─────────────────────────────────────────┘
        │                       │
        ▼                       ▼
┌──────────────┐        ┌──────────────┐
│ Model Store  │        │ Vector DB    │
│ (Distributed)│        │ (Milvus)     │
└──────────────┘        └──────────────┘
```

---

## 3. 模块设计

### 3.1 核心模块

#### 3.1.1 查询重写模块 (Query Rewriter)

**功能**: 将用户的自然语言问题转换为结构化查询

**输入**: 用户原始问题（字符串）
```python
input_text: str = "老板拖欠工资三个月，我该怎么办？"
```

**输出**: 结构化查询对象
```python
@dataclass
class RewrittenQuery:
    """重写后的查询结构"""
    keywords_for_search: List[str]      # 关键词列表
    query_for_vector_search: str        # 向量检索查询
    original_query: str                  # 原始问题
    confidence: float                    # 置信度 [0-1]
    metadata: Dict[str, Any]             # 元数据

# 输出示例
RewrittenQuery(
    keywords_for_search=["劳动报酬", "拖欠工资", "劳动争议"],
    query_for_vector_search="用人单位拖欠劳动报酬的法律责任和救济途径",
    original_query="老板拖欠工资三个月，我该怎么办？",
    confidence=0.92,
    metadata={"processing_time": 0.15}
)
```

**核心类设计**:
```python
class QueryRewriter:
    """查询重写器
    
    使用LoRA微调的小型语言模型，将口语化问题转换为
    适合检索系统的结构化查询。
    
    Attributes:
        model: 查询重写模型
        tokenizer: 分词器
        config: 配置对象
        device: 运行设备
    """
    
    def __init__(self, model_path: str, config: Config):
        """初始化查询重写器
        
        Args:
            model_path: 模型路径
            config: 配置对象
        """
        self.model = self._load_model(model_path)
        self.tokenizer = self._load_tokenizer(model_path)
        self.config = config
        self.device = config.model.device
    
    def rewrite(self, query: str) -> RewrittenQuery:
        """重写查询
        
        Args:
            query: 原始用户问题
        
        Returns:
            RewrittenQuery: 重写后的结构化查询
        
        Raises:
            ValueError: 输入为空或无效
            RuntimeError: 模型推理失败
        """
        pass
    
    def batch_rewrite(self, queries: List[str]) -> List[RewrittenQuery]:
        """批量重写查询
        
        Args:
            queries: 问题列表
        
        Returns:
            重写结果列表
        """
        pass
```

**关键算法**:
```python
def _generate_structured_query(self, text: str) -> Dict:
    """生成结构化查询的核心算法
    
    流程:
    1. 构建Prompt模板
    2. 模型推理生成JSON
    3. 解析和验证JSON
    4. 返回结构化结果
    """
    prompt = self._build_prompt(text)
    
    # 模型推理
    with torch.no_grad():
        outputs = self.model.generate(
            **self.tokenizer(prompt, return_tensors="pt").to(self.device),
            max_new_tokens=512,
            do_sample=True,
            temperature=0.1,
            top_p=0.95,
            stopping_criteria=self._get_stopping_criteria()
        )
    
    # 解析输出
    response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
    structured_data = self._extract_json(response)
    
    # 验证
    self._validate_output(structured_data)
    
    return structured_data
```

#### 3.1.2 混合检索模块 (Hybrid Retriever)

**功能**: 融合向量检索和关键词检索，返回最相关的法律条文

**架构设计**:
```
                  混合检索器
                      │
        ┌─────────────┴─────────────┐
        ▼                           ▼
  向量检索模块               关键词检索模块
  ┌──────────┐               ┌──────────┐
  │Embedding │               │Inverted  │
  │  Model   │               │  Index   │
  └────┬─────┘               └────┬─────┘
       │                          │
       │  ┌──────────┐            │
       └─►│  FAISS   │            │
          │  Index   │            │
          └────┬─────┘            │
               │                  │
               └─────────┬────────┘
                         ▼
                    融合与重排序
                         │
                         ▼
                   Top-K 结果
```

**核心类设计**:
```python
class HybridRetriever:
    """混合检索器
    
    结合向量语义检索和关键词精确匹配，提供高召回、高准确的检索服务。
    
    Attributes:
        embedding_model: 文本嵌入模型
        faiss_index: FAISS向量索引
        inverted_index: 倒排索引
        chunk_map: chunk ID到内容的映射
        config: 配置对象
    """
    
    def __init__(
        self,
        embedding_model_path: str,
        faiss_index_path: str,
        chunk_map_path: str,
        config: RetrieverConfig
    ):
        """初始化混合检索器"""
        self.embedding_model = self._load_embedding_model(embedding_model_path)
        self.faiss_index = self._load_faiss_index(faiss_index_path)
        self.chunk_map = self._load_chunk_map(chunk_map_path)
        self.inverted_index = self._build_inverted_index()
        self.config = config
    
    def search(
        self,
        query_for_vector: str,
        keywords_for_search: List[str],
        top_k: int = 5
    ) -> List[SearchResult]:
        """执行混合检索
        
        Args:
            query_for_vector: 向量检索查询
            keywords_for_search: 关键词列表
            top_k: 返回结果数量
        
        Returns:
            SearchResult列表，按相关性排序
        """
        # 并行执行两路检索
        vector_results = self._vector_search(query_for_vector, top_k * 2)
        keyword_results = self._keyword_search(keywords_for_search, top_k * 2)
        
        # 融合和重排序
        merged_results = self._fuse_and_rerank(
            vector_results,
            keyword_results,
            keyword_weight=self.config.keyword_weight,
            vector_weight=self.config.vector_weight
        )
        
        return merged_results[:top_k]
```

**数据结构**:
```python
@dataclass
class SearchResult:
    """检索结果"""
    chunk_id: int                    # chunk ID
    article_number: str              # 法条编号
    content: str                     # 法条内容
    score: float                     # 相关性得分
    source: str                      # 来源（vector/keyword/hybrid）
    keywords_matched: List[str]      # 匹配的关键词
    vector_score: float              # 向量检索得分
    keyword_score: float             # 关键词检索得分
```

**检索算法**:
```python
def _fuse_and_rerank(
    self,
    vector_results: List[Tuple[int, float]],
    keyword_results: List[Tuple[int, float]],
    keyword_weight: float = 0.7,
    vector_weight: float = 0.3
) -> List[SearchResult]:
    """融合和重排序算法
    
    使用加权融合策略:
    final_score = keyword_weight * keyword_score + vector_weight * vector_score
    
    Args:
        vector_results: 向量检索结果 [(doc_id, score), ...]
        keyword_results: 关键词检索结果 [(doc_id, score), ...]
        keyword_weight: 关键词权重
        vector_weight: 向量权重
    
    Returns:
        融合后的检索结果
    """
    fused_scores = {}
    
    # 归一化分数
    vector_results = self._normalize_scores(vector_results)
    keyword_results = self._normalize_scores(keyword_results)
    
    # 加权融合
    for doc_id, score in keyword_results:
        fused_scores[doc_id] = {
            'keyword_score': score,
            'vector_score': 0.0,
            'total': score * keyword_weight
        }
    
    for doc_id, score in vector_results:
        if doc_id in fused_scores:
            fused_scores[doc_id]['vector_score'] = score
            fused_scores[doc_id]['total'] += score * vector_weight
        else:
            fused_scores[doc_id] = {
                'keyword_score': 0.0,
                'vector_score': score,
                'total': score * vector_weight
            }
    
    # 排序
    sorted_results = sorted(
        fused_scores.items(),
        key=lambda x: x[1]['total'],
        reverse=True
    )
    
    # 构建SearchResult对象
    return [self._build_search_result(doc_id, scores) 
            for doc_id, scores in sorted_results]
```

#### 3.1.3 答案生成模块 (Answer Generator)

**功能**: 基于检索到的法条生成专业、易懂的法律解答

**核心类设计**:
```python
class LegalAnswerGenerator:
    """法律答案生成器
    
    使用LoRA微调的语言模型，基于检索到的法条生成
    专业且通俗易懂的法律咨询答案。
    
    Attributes:
        model: 答案生成模型
        tokenizer: 分词器
        config: 配置对象
        prompt_template: Prompt模板
    """
    
    def __init__(self, model_path: str, config: Config):
        """初始化答案生成器"""
        self.model = self._load_model(model_path)
        self.tokenizer = self._load_tokenizer(model_path)
        self.config = config
        self.prompt_template = self._load_prompt_template()
    
    def generate(
        self,
        query: str,
        retrieved_articles: List[SearchResult],
        conversation_history: Optional[List[Dict]] = None
    ) -> GeneratedAnswer:
        """生成法律答案
        
        Args:
            query: 用户问题
            retrieved_articles: 检索到的法条
            conversation_history: 对话历史（可选）
        
        Returns:
            GeneratedAnswer: 生成的答案对象
        """
        # 构建上下文
        context = self._assemble_context(retrieved_articles)
        
        # 构建Prompt
        prompt = self._build_prompt(
            query=query,
            context=context,
            history=conversation_history
        )
        
        # 生成答案
        with torch.no_grad():
            outputs = self.model.generate(
                **self.tokenizer(prompt, return_tensors="pt").to(self.device),
                max_new_tokens=1024,
                do_sample=True,
                temperature=0.7,
                top_p=0.95,
                repetition_penalty=1.1
            )
        
        # 解析输出
        answer_text = self._extract_answer(outputs)
        
        # 后处理
        answer_text = self._postprocess(answer_text)
        
        return GeneratedAnswer(
            text=answer_text,
            referenced_articles=retrieved_articles,
            confidence=self._estimate_confidence(answer_text),
            metadata={"model": "SLM-Generator"}
        )
```

**数据结构**:
```python
@dataclass
class GeneratedAnswer:
    """生成的答案"""
    text: str                              # 答案文本
    referenced_articles: List[SearchResult]# 引用的法条
    confidence: float                      # 置信度
    metadata: Dict[str, Any]               # 元数据
    generation_time: float                 # 生成耗时
```

**Prompt模板设计**:
```python
SYSTEM_PROMPT = """
你是一名顶级的中国法律AI专家。你的核心任务是严格、仅根据提供的'参考法条'，
为'用户问题'生成一个专业、严谨、详细并且通俗易懂的回答。

### 回答规则:
1. **结构清晰**: 条理清晰并且详细，建议分点阐述
2. **语言要求**: 使用清晰、准确的简体中文，禁止使用英文单词
3. **引用法条**: 明确标注引用的法律条文
4. **保持客观**: 作为AI助手，保持中立和客观
5. **实用建议**: 提供可操作的具体建议

### 回答格式:
一、核心结论
二、法律依据
三、具体建议
四、注意事项
"""

USER_PROMPT_TEMPLATE = """
参考法条：
{context}

用户问题：
{query}

请根据以上法条，为用户问题提供专业解答：
"""
```

### 3.2 支撑模块

#### 3.2.1 配置管理模块 (Config Manager)

**功能**: 统一管理系统配置，支持多环境、热更新

**类设计**:
```python
class ConfigManager:
    """配置管理器
    
    支持从多种来源加载配置：
    - 配置文件（YAML/JSON）
    - 环境变量
    - 命令行参数
    - 配置中心（规划中）
    """
    
    def __init__(self, config_path: Optional[str] = None):
        """初始化配置管理器"""
        self.config = self._load_config(config_path)
        self._watchers = []
    
    def get(self, key: str, default: Any = None) -> Any:
        """获取配置项"""
        pass
    
    def set(self, key: str, value: Any) -> None:
        """设置配置项"""
        pass
    
    def reload(self) -> None:
        """重新加载配置"""
        pass
    
    def watch(self, callback: Callable) -> None:
        """监听配置变更"""
        pass
```

#### 3.2.2 日志系统 (Logging System)

**功能**: 结构化日志记录，支持多级别、多输出

**设计**:
```python
class StructuredLogger:
    """结构化日志记录器
    
    遵循openEuler日志规范：
    - 统一格式
    - 分级记录
    - 支持追踪
    """
    
    LOG_FORMAT = {
        'timestamp': '%(asctime)s',
        'level': '%(levelname)s',
        'module': '%(name)s',
        'function': '%(funcName)s',
        'line': '%(lineno)d',
        'message': '%(message)s',
        'trace_id': '%(trace_id)s'
    }
    
    def __init__(self, name: str, config: SystemConfig):
        """初始化日志记录器"""
        self.logger = logging.getLogger(name)
        self._setup_handlers(config)
    
    def info(self, msg: str, **kwargs):
        """记录INFO级别日志"""
        self.logger.info(msg, extra=kwargs)
    
    def error(self, msg: str, exc_info: bool = True, **kwargs):
        """记录ERROR级别日志"""
        self.logger.error(msg, exc_info=exc_info, extra=kwargs)
```

#### 3.2.3 缓存服务 (Cache Service)

**功能**: 缓存常见查询结果，提升响应速度

**设计**:
```python
class CacheService:
    """缓存服务
    
    支持多级缓存：
    - L1: 内存缓存（LRU）
    - L2: 文件缓存
    - L3: Redis缓存（规划中）
    """
    
    def __init__(self, config: SystemConfig):
        """初始化缓存服务"""
        self.memory_cache = LRUCache(maxsize=1000)
        self.file_cache = FileCache(config.cache_dir)
    
    def get(self, key: str) -> Optional[Any]:
        """获取缓存"""
        # L1缓存
        if key in self.memory_cache:
            return self.memory_cache[key]
        
        # L2缓存
        value = self.file_cache.get(key)
        if value:
            self.memory_cache[key] = value
            return value
        
        return None
    
    def set(self, key: str, value: Any, ttl: int = 3600):
        """设置缓存"""
        self.memory_cache[key] = value
        self.file_cache.set(key, value, ttl)
```

### 3.3 工具模块

#### 3.3.1 数据预处理工具

**功能**: 法律文本预处理、分块、增强

```python
class LegalTextProcessor:
    """法律文本处理器"""
    
    @staticmethod
    def chunk_by_article(text: str) -> List[str]:
        """按法条分块"""
        pattern = r'(?=(第[一二三四五六七八九十零百千\d]+条))'
        parts = re.split(pattern, text)
        return [p for p in parts if p.strip()]
    
    @staticmethod
    def extract_keywords(text: str) -> List[str]:
        """提取关键词"""
        # 使用jieba分词 + TF-IDF
        pass
    
    @staticmethod
    def generate_hypothetical_questions(article: str, num: int = 5) -> List[str]:
        """生成假设性问题（HyDE）"""
        pass
```

#### 3.3.2 模型评估工具

**功能**: 评估模型性能，生成评估报告

```python
class ModelEvaluator:
    """模型评估器"""
    
    def evaluate_retrieval(
        self,
        retriever: HybridRetriever,
        test_dataset: List[TestCase]
    ) -> Dict[str, float]:
        """评估检索性能
        
        指标:
        - Recall@K
        - Precision@K
        - MRR (Mean Reciprocal Rank)
        - NDCG (Normalized Discounted Cumulative Gain)
        """
        pass
    
    def evaluate_generation(
        self,
        generator: LegalAnswerGenerator,
        test_dataset: List[TestCase]
    ) -> Dict[str, float]:
        """评估生成质量
        
        指标:
        - BLEU
        - ROUGE
        - BERTScore
        - Human Evaluation
        """
        pass
```

---

## 4. 接口设计

### 4.1 内部接口

#### 4.1.1 查询重写接口

```python
class IQueryRewriter(ABC):
    """查询重写器接口"""
    
    @abstractmethod
    def rewrite(self, query: str) -> RewrittenQuery:
        """重写单个查询"""
        pass
    
    @abstractmethod
    def batch_rewrite(self, queries: List[str]) -> List[RewrittenQuery]:
        """批量重写查询"""
        pass
```

#### 4.1.2 检索器接口

```python
class IRetriever(ABC):
    """检索器接口"""
    
    @abstractmethod
    def search(
        self,
        query: str,
        top_k: int = 5
    ) -> List[SearchResult]:
        """执行检索"""
        pass
    
    @abstractmethod
    def add_documents(self, documents: List[Dict]) -> None:
        """添加文档到索引"""
        pass
```

#### 4.1.3 生成器接口

```python
class IGenerator(ABC):
    """答案生成器接口"""
    
    @abstractmethod
    def generate(
        self,
        query: str,
        context: str
    ) -> GeneratedAnswer:
        """生成答案"""
        pass
```

### 4.2 外部接口

#### 4.2.1 RESTful API

**接口规范**: 遵循OpenAPI 3.0标准

```yaml
openapi: 3.0.0
info:
  title: LAW MASTER API
  version: 1.0.0
  description: 智能法律助手API

servers:
  - url: https://api.lawmaster.ai/v1
    description: 生产环境
  - url: http://localhost:8000/v1
    description: 开发环境

paths:
  /query:
    post:
      summary: 提交法律问题查询
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              properties:
                question:
                  type: string
                  description: 用户问题
                  example: "老板拖欠工资怎么办？"
                session_id:
                  type: string
                  description: 会话ID（可选）
                top_k:
                  type: integer
                  description: 返回法条数量
                  default: 5
              required:
                - question
      responses:
        '200':
          description: 查询成功
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/QueryResponse'
        '400':
          description: 请求参数错误
        '500':
          description: 服务器内部错误

components:
  schemas:
    QueryResponse:
      type: object
      properties:
        request_id:
          type: string
          description: 请求ID
        answer:
          type: string
          description: 法律答案
        referenced_articles:
          type: array
          items:
            $ref: '#/components/schemas/LegalArticle'
        confidence:
          type: number
          format: float
          description: 置信度
        processing_time:
          type: number
          format: float
          description: 处理耗时（秒）
    
    LegalArticle:
      type: object
      properties:
        article_number:
          type: string
          description: 法条编号
          example: "中华人民共和国民法典第五百七十九条"
        content:
          type: string
          description: 法条内容
        relevance_score:
          type: number
          format: float
          description: 相关性得分
```

#### 4.2.2 Python SDK接口

```python
class LawMasterClient:
    """LAW MASTER Python客户端"""
    
    def __init__(self, api_key: str, base_url: str = "https://api.lawmaster.ai/v1"):
        """初始化客户端
        
        Args:
            api_key: API密钥
            base_url: API基础URL
        """
        self.api_key = api_key
        self.base_url = base_url
        self.session = requests.Session()
        self.session.headers.update({"Authorization": f"Bearer {api_key}"})
    
    def query(
        self,
        question: str,
        session_id: Optional[str] = None,
        top_k: int = 5
    ) -> QueryResponse:
        """提交法律问题查询
        
        Args:
            question: 用户问题
            session_id: 会话ID（可选）
            top_k: 返回法条数量
        
        Returns:
            QueryResponse: 查询结果
        
        Raises:
            APIError: API调用失败
        
        Examples:
            >>> client = LawMasterClient(api_key="your_key")
            >>> response = client.query("老板拖欠工资怎么办？")
            >>> print(response.answer)
        """
        payload = {
            "question": question,
            "top_k": top_k
        }
        if session_id:
            payload["session_id"] = session_id
        
        try:
            resp = self.session.post(
                f"{self.base_url}/query",
                json=payload,
                timeout=30
            )
            resp.raise_for_status()
            return QueryResponse.from_dict(resp.json())
        except requests.RequestException as e:
            raise APIError(f"API调用失败: {e}")
```

### 4.3 数据接口

#### 4.3.1 向量数据库接口

```python
class VectorStore(ABC):
    """向量存储抽象接口"""
    
    @abstractmethod
    def add(self, vectors: np.ndarray, ids: List[int]) -> None:
        """添加向量"""
        pass
    
    @abstractmethod
    def search(
        self,
        query_vector: np.ndarray,
        k: int
    ) -> Tuple[np.ndarray, np.ndarray]:
        """检索最近邻向量
        
        Returns:
            (distances, indices)
        """
        pass
    
    @abstractmethod
    def delete(self, ids: List[int]) -> None:
        """删除向量"""
        pass
```

#### 4.3.2 知识库接口

```python
class KnowledgeBase(ABC):
    """知识库抽象接口"""
    
    @abstractmethod
    def get_article(self, article_id: str) -> Optional[LegalArticle]:
        """获取法条"""
        pass
    
    @abstractmethod
    def search_by_keywords(
        self,
        keywords: List[str],
        limit: int = 10
    ) -> List[LegalArticle]:
        """按关键词检索"""
        pass
    
    @abstractmethod
    def update_article(self, article: LegalArticle) -> None:
        """更新法条"""
        pass
```

---

## 5. 数据结构设计

### 5.1 核心数据结构

#### 5.1.1 查询相关

```python
@dataclass
class UserQuery:
    """用户查询"""
    query_id: str                    # 查询ID
    text: str                        # 查询文本
    user_id: Optional[str]           # 用户ID
    session_id: Optional[str]        # 会话ID
    timestamp: datetime              # 时间戳
    metadata: Dict[str, Any]         # 元数据
    
    def to_dict(self) -> Dict:
        """转换为字典"""
        return asdict(self)
    
    @classmethod
    def from_dict(cls, data: Dict) -> 'UserQuery':
        """从字典创建"""
        return cls(**data)


